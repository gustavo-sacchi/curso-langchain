# LCEL (LangChain Expression Language)

Como falamos anteriormente, os Runnables são os unidades básicas de trabalho do LangChain, ou seja, é um protocolo que implementa as interfaces de `invoke`, `stream` e `batch` bem como suas variantes assíncronas. 

Além disso, o LangChain implementa a forma declarativa de compor cadeias utilizando o operador pipe "|".

Vantagens de utilizar a forma declarativa:

- **Suporte de streaming de primeira classe**: Quando você constrói suas cadeias com LCEL, você obtém o melhor time-to-first-token possível (tempo decorrido até que o primeiro pedaço de saída saia).
- **Suporte assíncrono**: Qualquer cadeia construída com LCEL pode ser chamada tanto com a API síncrona quanto com a API assíncrona. Isso permite usar o mesmo código para protótipos e em produção, com ótimo desempenho e a capacidade de lidar com muitas solicitações simultâneas no mesmo servidor.
- **Execução paralela otimizada**.
- **Novas tentativas e fallbacks**: você consegue configurar novas tentativas e fallbacks para qualquer parte da sua cadeia LCEL.
- **Acessar resultados intermediários**: Para cadeias mais complexas, geralmente é muito útil acessar os resultados de etapas intermediárias antes mesmo que a saída final seja produzida.
- **Esquemas de entrada e saída**: Os esquemas de entrada e saída fornecem a cada cadeia LCEL esquemas Pydantic e JSONSchema inferidos da estrutura da sua cadeia.

Cada componente é conectado usando o operador pipe "|" (ou usando `.pipe()`) , ou seja, ele cria a arquitetura de pipeline, onde a saída de uma função (ou componente) é tratado como entrada de proxima função (ou, componente), permitindo criar uma cadeia (chain) sequencial de ações.

O jeito mais fácil de entender é por meio do exemplo mais simples:

1) Sabemos que o prompt é entrada de um LLM,
2) E que o LLM gera um texto,
3) Logo, você consegue encadear ambos componentes:

```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o-mini")

prompt = ChatPromptTemplate.from_template("Conte-me uma piada sobre {topico}")

chain = prompt | model | StrOutputParser() 

chain.invoke({"topico": "palhaços"})

```
 Aqui a entrada do usuário é recebido por `prompt` transformando a entrada + prompt numa string para ser enviada ao LLM (`model`) que por sua vez gera um texto em string, e pode ser formatado para o usuário usando um analisador de saída `StrOutputParser()`. ao final, o print do invoke da chain será o resultado da geração do LLM.

Todas essas definições ficarão mais claras durante o curso,

Sabendo que os componentes seguem essa possibilidade de encadeamento, é importante entender sobre o elemento base da criação de cada componente e permite esse tipo de formatação uma vez que você poderá criar suas próprias funções e precisará formatá-las no estilo de executáveis (`runnables`) para que você possa adicionar suas funções customizadas dentro da chain.

Então agora vamos conhecer o que é o protocolo [Runnable](https://python.langchain.com/api_reference/core/runnables.html).

# Runnables:

### RunnableSequence

- Serve para invocar uma cadeia sequencia onde a saída de um componente serve de entrada para o próximo componente.
- **RunnableSequence** é o operador de composição mais importante no LangChain, pois é usado em praticamente todas as cadeias.
-  Um RunnableSequence pode ser instanciado diretamente ou, mais comumente, usando o operador | , onde os operandos esquerdo ou direito (ou ambos) devem ser um componente com base Runnable.

```python
runnable_seq = componente1 | componente2
```

Exemplo:
```python
# Veja o que é o RunnableLambda abaixo.
from langchain_core.runnables import RunnableLambda

def add_one(x: int) -> int:
    return x + 1

def mul_two(x: int) -> int:
    return x * 2

runnable_1 = RunnableLambda(add_one)
runnable_2 = RunnableLambda(mul_two)
sequence = runnable_1 | runnable_2
# Or equivalently:
# sequence = RunnableSequence(first=runnable_1, last=runnable_2)
resposta = sequence.invoke(1)
print(resposta)
```
### RunnableLambda

- RunnableLambda converte um python `callable` (pode-se entender aqui, a principio, como qualquer 'função' python) em um Runnable.
- Esse executável envolve o `callable` para que você possa utilizar ele em uma sequencia de componentes de LangChain

Exemplo:

Imagine que eu quero usar na minha Chain a seguinte função personalizada: `add_one`. Ela no caso não seque os padrões do protocolo `runnable`, ou seja, precisamos transformar ela em um executável langchain. Dessa forma encapsulamos nossa função em um `RunnableLambda`. Em teoria estamos transformando nossa função criada em uma função do estilo `lambda` do python.

```python
from langchain_core.runnables import RunnableLambda

# Função customizada
def add_one(x: int) -> int:
    return x + 1

runnable = RunnableLambda(add_one) # agora eu implementei os protocolos padrões do langchain, exemplo o invoke.

resposta = runnable.invoke(1) # returns 2

print(resposta)
```

### RunnableParallel

- Serve para executar componentes (ou operações) de forma paralela, quando ambos recebem o mesmo tipo de entrada. 
- Normalmente é representado por um dicionário usando chaves "{ ... }", desde que não seja inicio de Chain, neste caso precisamos declarar usando `RunnableParallel` literalmente ao invés de usar dicionários .

```python
runnable = RunnableParallel(chave1=operação1, chave2=operação2)
```

Exemplo:
```python
from langchain_core.runnables import RunnableLambda

def add_one(x: int) -> int:
    return x + 1

def mul_two(x: int) -> int:
    return x * 2

def mul_three(x: int) -> int:
    return x * 3

runnable_1 = RunnableLambda(add_one)
runnable_2 = RunnableLambda(mul_two)
runnable_3 = RunnableLambda(mul_three)

sequence = runnable_1 | {  # o dicionário aqui é entendido como 'RunnableParallel'
    "mul_two": runnable_2,
    "mul_three": runnable_3,
}
# Ou usando o equivalente:
# sequence = runnable_1 | RunnableParallel(
#     {"mul_two": runnable_2, "mul_three": runnable_3}
# )
# Ou também o equivalente:
# sequence = runnable_1 | RunnableParallel(
#     mul_two=runnable_2,
#     mul_three=runnable_3,
# )

resposta = sequence.invoke(1)
print(resposta)
```
### RunnablePassthrough

- Executável para passar entradas inalteradas ou com chaves adicionais.
- Ao compor cadeias com várias etapas, às vezes você vai querer passar dados de etapas anteriores inalterados para uso como entrada para uma etapa posterior. A classe  `RunnablePassthrough` permite que você faça exatamente isso, e é tipicamente usada em conjunto com um `RunnableParallel` para passar dados para uma etapa posterior em suas cadeias construídas.

Exemplo 1: Sem transformar a entrada. 

```python
from langchain_core.runnables import RunnablePassthrough

chain = RunnablePassthrough() | RunnablePassthrough() | RunnablePassthrough ()

# Independente de quantas vezes você "passar o resultado para frente", a entrada não é alterada.

resposta = chain.invoke("Olá")

print(resposta) # retorna Olá
```

Exemplo 2: Transformando a entrada.

```python
from langchain_core.runnables import RunnablePassthrough

def entrada_para_letras_maiusculas(entrada: str):
	saida = entrada.upper()
	return saida

chain = RunnablePassthrough() | RunnableLambda(entrada_para_letras_maiusculas) | RunnablePassthrough ()

# Neste caso vamos receber a entrada do usuário, passar para a função 'entrada_para_letras_maiusculas', transformar olá -> OLÁ e passar para frente.

resposta = chain.invoke("olá")

print(resposta) # retorna OLÁ
```

### Operador Assign
- Normalmente é usado com a combinação `RunnablePassthrough.assign()` para que você possa criar uma saída em dicionário que será usada como entrada ao próximo componente com tal que você tenha a entrada inalterada e uma outra chave com a entrada transformada.

Exemplo:

```python
# https://python.langchain.com/docs/how_to/assign/

from langchain_core.runnables import RunnableParallel, RunnablePassthrough

runnable = RunnableParallel(
    extra=RunnablePassthrough.assign(mult=lambda x: x["num"] * 3),
    modified=lambda x: x["num"] + 1,
)

runnable = RunnablePassthrough() | RunnablePassthrough.assign(multiplica_3=lambda x: x["num"] * 3)

resposta = runnable.invoke({"num": 1})

print(resposta) # Saida {"num": 1, "multiplica_3": 3}
```


Vamos tentar unir tudo o que aprendemos num exemplo maior e que fará você entender quando construirmos chains mais complexas? Vamos lá.

Processo:
1) Receber a entrada do tipo {"input": "Parabéns Você"}  e passar para frente (testar uso do RunnablePassthrough)
2) Quando eu receber a entrada de (1) eu gostaria de criar um dicionário mantendo a entrada de (1) intacta, mas criando uma chave nova  ("num_caract") tal que seja a entrada de (1) contando o total de caracteres.
3) Usando a saída de (2) quero paralelizar a entrada em dois processos, o primeiro, pegando a entrada textual e adicionando a palavra " Conseguiu!" numa chave chamada "transformar_entrada" o segundo não farei nada, apenas passarei para frente a entrada sem qualquer alteração numa chave "passa_para_frente".
4) Por fim, vou passar para frente a combinação do processo paralelo e imprimir o resultado.


```python
from langchain_core.runnables import RunnableLambda, RunnablePassthrough, RunnableParallel  
  
""" Desafio com Runnables:  """
  
# Parte 1  
parte_1_runnable = RunnablePassthrough()  
  
# Parte 2  
def conta_caracteres(entrada: dict) -> int:  
    return len(entrada["input"])  
  
convert_funcao = RunnableLambda(conta_caracteres)  
  
parte_2_runnable = RunnablePassthrough.assign(num_caract=convert_funcao)  
  
# Parte 3  
def transforma(entrada: dict) -> str:  
    resultado = entrada["input"] + " Conseguiu!"  
    return resultado  
  
parte_3_transforma_entrada = RunnableLambda(transforma)  
parte_3_passa_para_frente = RunnablePassthrough()  
  
parte_3_runnable = RunnableParallel({  
    "transformar_entrada": parte_3_transforma_entrada,  
    "passa_para_frente": parte_3_passa_para_frente  
}  
)  
  
# Parte 4  
parte_4_runnable = RunnablePassthrough()  
  
# Unindo tudo:  
  
chain = parte_1_runnable | parte_2_runnable | parte_3_runnable | parte_4_runnable  
  
## Invocar:  
  
  
resposta = chain.invoke({"input": "Parabéns Você"})  
  
print("------ RESPOSTA DO DESAFIO -----------------------")  
print(resposta)  
print("--------------------------------------------------")

```

Esse exemplo será bastante importante para entender o processo de RAG.

Existem outros executáveis mais complexos e que também usaremos ao longo desse curso, por exemplo,  quando você deseja trabalhar com memória usamos `RunnableWithMessageHistory` (documentação [link](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html)) para criar um gestor de memória da nossa chain, ou seja, ele é responsável de recuperar e atualizar o histórico de um chat sem que precisemos fazer isso à mão, mas deixaremos para explicar quando fomos utilizá-la.